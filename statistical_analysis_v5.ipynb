{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train_FD004.csv', low_memory=False)\n",
    "\n",
    "# Define a function to calculate Fisher score using first 50 and last 50 samples of each engine\n",
    "def fisher_score_sensor(df, sensor, start_cycles=50, end_cycles=50):\n",
    "    begin_life = df[df['time, in cycles'] <= start_cycles][sensor]\n",
    "    end_life = df[df['time, in cycles'] >= (df['time, in cycles'].max() - end_cycles + 1)][sensor]\n",
    "    mean_diff = abs(begin_life.mean() - end_life.mean())\n",
    "    within_var = begin_life.var() + end_life.var()\n",
    "    return mean_diff / within_var\n",
    "\n",
    "# Apply Fisher score calculation across each sensor\n",
    "sensor_columns = [col for col in train.columns if col.startswith('sensor')]\n",
    "fisher_scores = {sensor: fisher_score_sensor(train, sensor) for sensor in sensor_columns}\n",
    "\n",
    "# Select the top sensors based on Fisher scores\n",
    "top_sensors = sorted(fisher_scores, key=fisher_scores.get, reverse=True)[:5]\n",
    "print(\"Top sensors selected based on Fisher score:\", top_sensors)\n",
    "\n",
    "# Calculate RUL for each engine\n",
    "train['RUL'] = train.groupby('unit number')['time, in cycles'].transform(lambda x: x.max() - x)\n",
    "\n",
    "# Apply EMA for each top sensor\n",
    "ema_span = 50\n",
    "for sensor in top_sensors:\n",
    "    train[f'{sensor}_EMA'] = train.groupby('unit number')[sensor].transform(lambda x: x.ewm(span=ema_span, adjust=False).mean())\n",
    "train = train[['unit number', 'time, in cycles'] + [f'{sensor}_EMA' for sensor in top_sensors] + ['RUL']]\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Add gradient columns to check for consecutive direction\n",
    "for sensor in top_sensors:\n",
    "    # Calculate the gradient between consecutive EMA points\n",
    "    train[f'{sensor}_EMA_gradient'] = train.groupby('unit number')[f'{sensor}_EMA'].diff()\n",
    "\n",
    "# Define function to check if EMA direction is consistent over 5 cycles\n",
    "def check_consistent_direction(df, sensor, window=5):\n",
    "    gradients = df[f'{sensor}_EMA_gradient']\n",
    "    direction = np.sign(gradients)\n",
    "    # Check if within a rolling window of 5, all directions are the same (either all 1 or all -1)\n",
    "    return direction.rolling(window=window).apply(lambda x: all(x == x[0]), raw=True).fillna(0).astype(bool)\n",
    "\n",
    "# Apply this function for each sensor and create a column indicating consistent direction over 5 cycles\n",
    "for sensor in top_sensors:\n",
    "    train[f'{sensor}_EMA_consistent_direction'] = train.groupby('unit number').apply(\n",
    "        lambda x: check_consistent_direction(x, sensor)\n",
    "    ).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_FD004_EMA_Gradient.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Check for 5 consecutive cycles with consistent direction, where at least 4 sensors are TRUE simultaneously for each engine\n",
    "    consecutive_cycles = 4\n",
    "    required_true_sensors = 3  # Minimum number of sensors required to have consecutive TRUE values simultaneously\n",
    "\n",
    "    output_dir = 'plots'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List to collect results for each engine\n",
    "    results = []\n",
    "\n",
    "    for engine_id, group in train.groupby('unit number'):\n",
    "        # Create a DataFrame of consistent directions for each sensor\n",
    "        consistent_directions = group[[f'{sensor}_EMA_consistent_direction' for sensor in top_sensors]]\n",
    "        \n",
    "        # Identify rows where at least 4 sensors are TRUE simultaneously\n",
    "        sufficient_sensors_true = (consistent_directions.sum(axis=1) >= required_true_sensors)\n",
    "        \n",
    "        # Find rolling windows where this condition is TRUE for all 5 consecutive cycles\n",
    "        consecutive_true = sufficient_sensors_true.rolling(window=consecutive_cycles).apply(lambda x: all(x), raw=True).fillna(0).astype(bool)\n",
    "        \n",
    "        # Get the index of the first cycle where the condition is met\n",
    "        valid_cycles = group.loc[consecutive_true].index.tolist()\n",
    "        Degradation_Onset = group.loc[valid_cycles[0], 'time, in cycles'] if valid_cycles else None\n",
    "        \n",
    "        # Print the first instance if it exists\n",
    "        if Degradation_Onset:\n",
    "            print(f\"Engine {engine_id} meets the condition first at cycle {Degradation_Onset}.\")\n",
    "        \n",
    "        # Plotting\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle(f'EMA Trend for Engine {engine_id}', fontsize=16)\n",
    "        \n",
    "        for i, sensor in enumerate(top_sensors):\n",
    "            ax = axs[i // 3, i % 3]\n",
    "            ema = group[f'{sensor}_EMA']\n",
    "            ax.plot(group['time, in cycles'], ema, 'o--',label='EMA', color='green')\n",
    "            \n",
    "            # Mark the first cycle that meets the condition\n",
    "            if Degradation_Onset:\n",
    "                ax.axvline(x=Degradation_Onset, color='red', linestyle='--', label='Degradation Onset')\n",
    "            \n",
    "            ax.set_title(sensor)\n",
    "            ax.set_xlabel('Cycles')\n",
    "            ax.set_ylabel('EMA')\n",
    "            ax.legend(loc='upper right')\n",
    "        \n",
    "        # Remove the last subplot if itâ€™s not used\n",
    "        fig.delaxes(axs[1, 2])\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.savefig(f\"{output_dir}/engine_{engine_id}_ema.png\", dpi=300)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Add results to the list\n",
    "        results.append({'unit number': engine_id, 'Degradation Onset': Degradation_Onset})\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV once\n",
    "    results_df = pd.DataFrame(results)\n",
    "    # Save the results to a CSV file with consecutive_cycles in the filename\n",
    "    results_df.to_csv(f'results_{consecutive_cycles}_cycles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Define a function to compare distribution similarity using KS test\n",
    "def ks_test_distribution_similarity(df, sensor, degradation_onset):\n",
    "    # Split data into before and after Degradation_Onset\n",
    "    before_degradation = df[df['time, in cycles'] < degradation_onset][f'{sensor}_EMA']\n",
    "    after_degradation = df[df['time, in cycles'] >= degradation_onset][f'{sensor}_EMA']\n",
    "    \n",
    "    # Apply KS test\n",
    "    if len(before_degradation) > 0 and len(after_degradation) > 0:\n",
    "        statistic, p_value = ks_2samp(before_degradation, after_degradation)\n",
    "    else:\n",
    "        statistic, p_value = None, None  # Not enough data\n",
    "    \n",
    "    return statistic, p_value\n",
    "\n",
    "# Dictionary to hold the KS test results for each sensor and each engine\n",
    "ks_test_results = []\n",
    "\n",
    "for engine_id, group in train.groupby('unit number'):\n",
    "    degradation_onset = results_df.loc[results_df['unit number'] == engine_id, 'Degradation Onset'].values[0]\n",
    "    \n",
    "    # Skip engines without a valid degradation onset\n",
    "    if pd.notnull(degradation_onset):\n",
    "        engine_results = {'unit number': engine_id, 'Degradation Onset': degradation_onset}\n",
    "        \n",
    "        for sensor in top_sensors:\n",
    "            statistic, p_value = ks_test_distribution_similarity(group, sensor, degradation_onset)\n",
    "            engine_results[f'{sensor}_KS_statistic'] = statistic\n",
    "            engine_results[f'{sensor}_p_value'] = p_value\n",
    "        \n",
    "        ks_test_results.append(engine_results)\n",
    "\n",
    "# Convert KS test results to a DataFrame\n",
    "ks_test_results_df = pd.DataFrame(ks_test_results)\n",
    "ks_test_results_df.to_csv('ks_test_results.csv', index=False)\n",
    "\n",
    "# Display summary of results\n",
    "for sensor in top_sensors:\n",
    "    significant_count = (ks_test_results_df[f'{sensor}_p_value'] < 0.05).sum()\n",
    "    print(f\"For {sensor}, {significant_count} engines have a significantly different distribution (p < 0.05) before and after Degradation_Onset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the sensor with the highest Fisher score\n",
    "highest_fisher_sensor = max(fisher_scores, key=fisher_scores.get)\n",
    "print(f\"Sensor with the highest Fisher score: {highest_fisher_sensor}\")\n",
    "\n",
    "# Create a DataFrame to store engines where the distribution is significantly different for the highest Fisher score sensor\n",
    "significant_engines = []\n",
    "\n",
    "for _, row in ks_test_results_df.iterrows():\n",
    "    # Extract KS statistic and p-value for the sensor with the highest Fisher score\n",
    "    ks_statistic = row[f'{highest_fisher_sensor}_KS_statistic']\n",
    "    p_value = row[f'{highest_fisher_sensor}_p_value']\n",
    "    engine_id = row['unit number']\n",
    "    \n",
    "    # Check if the distribution is significantly different (p-value < 0.05)\n",
    "    if pd.notnull(p_value) and p_value < 0.05:\n",
    "        significant_engines.append({\n",
    "            'unit number': engine_id,\n",
    "            'KS statistic': ks_statistic,\n",
    "            'p-value': p_value,\n",
    "            'Inference': 'Significantly Different' if p_value < 0.05 else 'Not Significantly Different'\n",
    "        })\n",
    "\n",
    "# Convert significant engines list to a DataFrame\n",
    "significant_engines_df = pd.DataFrame(significant_engines)\n",
    "\n",
    "# Save the significant results DataFrame to a CSV file\n",
    "significant_engines_df.to_csv(f'significant_engines_{highest_fisher_sensor}.csv', index=False)\n",
    "\n",
    "# Display summary\n",
    "print(f\"Engines with significant distribution difference for {highest_fisher_sensor} sensor:\")\n",
    "significant_engines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fd004 = pd.read_csv('train_FD004.csv', low_memory=False)\n",
    "train_fd004.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of sensor 16 from the original training data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_fd004['sensor measurement 16'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Sensor 16')\n",
    "plt.xlabel('Sensor 16')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('sensor_16_histogram.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of sensor 16 from the original training data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['sensor measurement 16_EMA'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Sensor 16')\n",
    "plt.xlabel('Sensor 16')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('sensor_16_histogram.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data for engine 1 for sensor 16\n",
    "engine1 = train_fd004[train_fd004['unit number'] == 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(engine1['time, in cycles'], engine1['sensor measurement 16'], 'o--', label='Sensor 16', color='skyblue')\n",
    "plt.title('Sensor 16 Time Series for Engine 1')\n",
    "plt.xlabel('Time, in cycles')\n",
    "plt.ylabel('Sensor 16')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('sensor_16_time_series.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data for engine 1 for sensor 16\n",
    "engine1 = train_fd004[train_fd004['unit number'] == 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(engine1['time, in cycles'], engine1['sensor measurement 16'], 'o--', label='Sensor 16', color='skyblue')\n",
    "plt.title('Sensor 16 Time Series for Engine 1')\n",
    "plt.xlabel('Time, in cycles')\n",
    "plt.ylabel('Sensor 16')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('sensor_16_time_series.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data for engine 1 for sensor 16 ema\n",
    "engine1 = train[train['unit number'] == 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(engine1['time, in cycles'], engine1['sensor measurement 16_EMA'], 'o--', label='Sensor 16 EMA', color='green')\n",
    "plt.title('Sensor 16 EMA Time Series for Engine 1')\n",
    "plt.xlabel('Time, in cycles')\n",
    "plt.ylabel('Sensor 16 EMA')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig('sensor_16_ema_time_series.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
